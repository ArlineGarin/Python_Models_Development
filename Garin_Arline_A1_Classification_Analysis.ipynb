{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h1>Case Challenge Part II</h1>\n",
    "<b>DAT-5303 | Machine Learning</b><br>\n",
    "Arline Garin<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import random            as rand                     # random number gen\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import numpy             as np \n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus                                     # interprets dot objects\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying the path and file name\n",
    "file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef = pd.read_excel(io = file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# mv_flagger\n",
    "#########################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm-COLUMN_NAME'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800, export = False):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    export     : bool, defalut False\n",
    "        whether or not to export the tree as a .png file\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width,\n",
    "                unconfined = True)\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the mislabeled column \n",
    "chef.rename(columns = {'LARGEST_ORDER_SIZE':'AVG_NB_MEALS'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Y-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                    ---------------------\n",
      "Suceeded Cross-Sell Promotion       | 1321\n",
      "Failed Cross-Sell Promotion         | 625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Differentiating success and failure of the promotion\n",
    "\n",
    "SUCCEEDED_PROMOTION   = len(chef['CROSS_SELL_SUCCESS'][chef['CROSS_SELL_SUCCESS'] == 1])\n",
    "FAILED_PROMOTION      = len(chef['CROSS_SELL_SUCCESS'][chef['CROSS_SELL_SUCCESS'] == 0])\n",
    "\n",
    "print(f\"\"\"\n",
    "                                    ---------------------\n",
    "Suceeded Cross-Sell Promotion       | {SUCCEEDED_PROMOTION}\n",
    "Failed Cross-Sell Promotion         | {FAILED_PROMOTION}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS_SELL_SUCCESS             1.00\n",
      "CANCELLATIONS_BEFORE_NOON      0.16\n",
      "MOBILE_NUMBER                  0.10\n",
      "TASTES_AND_PREFERENCES         0.08\n",
      "REFRIGERATED_LOCKER            0.07\n",
      "PC_LOGINS                      0.04\n",
      "MASTER_CLASSES_ATTENDED        0.04\n",
      "PACKAGE_LOCKER                 0.04\n",
      "CONTACTS_W_CUSTOMER_SERVICE    0.04\n",
      "MEDIAN_MEAL_RATING             0.03\n",
      "AVG_PREP_VID_TIME              0.03\n",
      "AVG_NB_MEALS                   0.02\n",
      "EARLY_DELIVERIES               0.02\n",
      "TOTAL_MEALS_ORDERED            0.01\n",
      "AVG_TIME_PER_SITE_VISIT        0.01\n",
      "TOTAL_PHOTOS_VIEWED            0.01\n",
      "LATE_DELIVERIES                0.01\n",
      "PRODUCT_CATEGORIES_VIEWED      0.00\n",
      "UNIQUE_MEALS_PURCH             0.00\n",
      "REVENUE                        0.00\n",
      "WEEKLY_PLAN                   -0.01\n",
      "AVG_CLICKS_PER_VISIT          -0.04\n",
      "CANCELLATIONS_AFTER_NOON      -0.05\n",
      "MOBILE_LOGINS                 -0.05\n",
      "Name: CROSS_SELL_SUCCESS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# creating a (Pearson) correlation matrix\n",
    "df_corr = chef.corr().round(2)\n",
    "\n",
    "\n",
    "# printing (Pearson) correlations with SalePrice\n",
    "print(df_corr.loc['CROSS_SELL_SUCCESS'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Missing Value Analysis and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Flagger uses in place in the function            \n",
    "chef = mv_flagger(chef)\n",
    "\n",
    "# Imputing NA's\n",
    "chef.loc[:,'FAMILY_NAME'].fillna('Unknown',inplace = True)\n",
    "\n",
    "\n",
    "# chef.columns # Checking which columns where created.\n",
    "\n",
    "# chef.isnull().any().any() # making sure all missing values have been taken care of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Measurement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Heuristics of classification:</b>\n",
    "\n",
    "- Continuous: Numerical values\n",
    "- Binary: Containing 1 and 0\n",
    "- Count or interval: How many of something was measured.\n",
    "- Discrete / Nominal: Unique variables.\n",
    "\n",
    "\n",
    "<b>Continuous</b>\n",
    "- REVENUE\n",
    "- AVG_TIME_PER_SITE_VISIT\n",
    "- AVG_PREP_VID_TIME\n",
    "- AVG_CLICKS_PER_VISIT\n",
    "\n",
    "<b>Binary</b>\n",
    "- CROSS-SELL SUCCESS\n",
    "- MOBILE_NUMBER\n",
    "- TASTES_AND_PREFERENCES\n",
    "- PACKAGE_LOCKER\n",
    "- REFRIGERATED_LOCKER\n",
    "\n",
    "<b>Count or Interval</b>\n",
    "- TOTAL_MEALS_ORDERED\n",
    "- UNIQUE_MEALS_PURCH\n",
    "- CONTACTS_W_CUSTOMER_SERVICE\n",
    "- PRODUCT_CATEGORIES_VIEWED\n",
    "- CANCELLATIONS_BEFORE_NOON\n",
    "- CANCELLATIONS_AFTER_NOON\n",
    "- PC_LOGINS\n",
    "- MOBILE_LOGINS\n",
    "- WEEKLY_PLAN\n",
    "- EARLY_DELIVERIES\n",
    "- LATE_DELIVERIES\n",
    "- AVG_NB_MEALS\n",
    "- MASTER_CLASSES_ATTENDED\n",
    "- TOTAL_PHOTOS_VIEWED\n",
    "- MEDIAN_MEAL_RATING\n",
    "\n",
    "<b>Discrete or Nominal</b>\n",
    "- NAME\n",
    "- EMAIL\n",
    "- FIRST_NAME\n",
    "- LAST_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chef.WEEKLY_PLAN.describe() # Count of weeks that a customer subscribed \n",
    "\n",
    "# It seems that users are not using the weekly meal plans! \n",
    "# chef[chef.WEEKLY_PLAN == 52]\n",
    "# chef.TOTAL_MEALS_ORDERED.describe()\n",
    "\n",
    "chef.loc[chef.TOTAL_MEALS_ORDERED > 95, ['WEEKLY_PLAN',\n",
    "                                      'NAME',\n",
    "                                      'TOTAL_MEALS_ORDERED',\n",
    "                                     'CROSS_SELL_SUCCESS']].sort_values('WEEKLY_PLAN',\n",
    "                                                ascending = False).groupby('CROSS_SELL_SUCCESS').mean()\n",
    "# It looks that there's no effective cross sell success for people that order a lot of meals\n",
    "\n",
    "chef['HIGH_TOTAL_MEALS_ORDERED'] = 0\n",
    "chef.loc[chef.TOTAL_MEALS_ORDERED > 95, 'HIGH_TOTAL_MEALS_ORDERED'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef.loc[chef.TOTAL_MEALS_ORDERED < 60, ['WEEKLY_PLAN',\n",
    "                                      'NAME',\n",
    "                                      'TOTAL_MEALS_ORDERED',\n",
    "                                     'CROSS_SELL_SUCCESS']].sort_values('WEEKLY_PLAN',\n",
    "                                            ascending = False).groupby('CROSS_SELL_SUCCESS').mean()\n",
    "# It looks that the Total Meals people that has ordered less than 60 meals are \n",
    "# slightly more prone to do succesfull cross sell \n",
    "\n",
    "chef['LOW_TOTAL_MEALS_ORDERED'] = 0\n",
    "chef.loc[chef.TOTAL_MEALS_ORDERED < 60, 'LOW_TOTAL_MEALS_ORDERED'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dummy variable for customers using the mobile app\n",
    "chef['USE_MOBILE_APP'] = 0\n",
    "chef.loc[chef.MOBILE_LOGINS > 0, 'USE_MOBILE_APP'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "\n",
    "# guessing gender based on (given) name\n",
    "\n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in chef ['FIRST_NAME']:\n",
    "    #guess = gender.Detector().get_gender(name)\n",
    "    #print(guess)\n",
    "    #placeholder_lst.append(guess)\n",
    "    \n",
    "# checking results\n",
    "#print(placeholder_lst)\n",
    "\n",
    "# Adding the guessed gender from gender_guesser.detector into a new column the dataframe \n",
    "chef['GENDER_GUESS'] = ['unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'mostly_male', 'female', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', 'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'andy', 'male', 'unknown', 'unknown', 'male', 'male', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'female', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'unknown', 'male', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'male', 'mostly_male', 'male', 'male', 'male', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'andy', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'female', 'male', 'male', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'unknown', 'mostly_female', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_male', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'mostly_male', 'unknown', 'unknown', 'male', 'andy', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'male', 'female', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'mostly_female', 'female', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'andy', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'male', 'unknown', 'male', 'unknown', 'mostly_male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'mostly_male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'andy', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown']\n",
    "\n",
    "# Checking results\n",
    "# chef['GENDER_GUESS'].value_counts()\n",
    "\n",
    "## OUTPUT\n",
    "# unknown          1385\n",
    "# male              381\n",
    "# female            125\n",
    "# mostly_male        24\n",
    "# mostly_female      21\n",
    "# andy               10\n",
    "# Name: GENDER_GUESS, dtype: int64\n",
    "\n",
    "# Reducing the number of \"unknown\" gender \n",
    "\n",
    "for index, row in chef.iterrows():\n",
    "\n",
    "    # First nested condition for Gender guessed as \"unknown\"\n",
    "    if 'unknown' in chef.loc[index, 'GENDER_GUESS']:\n",
    "\n",
    "        if chef.loc[index, 'FIRST_NAME'].endswith('a'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('o'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('r'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('d'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('lin'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "\n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('lyn'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('on'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('os'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('ne'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('en'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('s'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('se'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('k'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('e'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "            \n",
    "        elif chef.loc[index, 'FIRST_NAME'].endswith('y'):\n",
    "            chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "    \n",
    "    # Second condition for Gender guessed as \"mostly_male\"\n",
    "    elif 'mostly_male' in chef.loc[index, 'GENDER_GUESS']:\n",
    "        chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "    \n",
    "    # Third condition for Gender guessed as \"mostly_female\"\n",
    "    elif 'mostly_female' in chef.loc[index, 'GENDER_GUESS']:\n",
    "        chef.loc[index, 'GENDER_GUESS'] = 'female'\n",
    "    \n",
    "    # Fourth condition for Gender guessed as \"andy\"\n",
    "    elif 'andy' in chef.loc[index, 'GENDER_GUESS']:\n",
    "        chef.loc[index, 'GENDER_GUESS'] = 'male'\n",
    "        \n",
    "# Checking results\n",
    "# chef['GENDER_GUESS'].value_counts()\n",
    "\n",
    "\n",
    "## OUTPUT\n",
    "# male       1082\n",
    "# female      516\n",
    "# unknown     348\n",
    "# Name: GENDER_GUESS, dtype: int64\n",
    "\n",
    "# categorical_boxplots(response = 'LOG_REVENUE', cat_var = 'GENDER_GUESS', data = chef)\n",
    "\n",
    "# one hot encoding GENDER categorical variable\n",
    "GENDER_DUMMIES       = pd.get_dummies(chef['GENDER_GUESS'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "chef = chef.drop('GENDER_GUESS', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "chef = chef.join([GENDER_DUMMIES])\n",
    "\n",
    "# saving new columns\n",
    "new_columns = chef.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the emails by domain knowledge provided by Customer Service Team\n",
    "professional = [\"mmm.com\", \"amex.com\", \"apple.com\", \"boeing.com\", \"caterpillar.com\",\n",
    "    \"chevron.com\", \"cisco.com\", \"cocacola.com\", \"disney.com\", \"dupont.com\",\n",
    "    \"exxon.com\", \"ge.org\", \"goldmansacs.com\", \"homedepot.com\", \"ibm.com\",\n",
    "    \"intel.com\", \"jnj.com\", \"jpmorgan.com\", \"mcdonalds.com\", \"merck.com\",\n",
    "    \"microsoft.com\", \"nike.com\", \"pfizer.com\", \"pg.com\", \"travelers.com\",\n",
    "    \"unitedtech.com\", \"unitedhealth.com\", \"verizon.com\", \"visa.com\",\n",
    "    \"walmart.com\"]\n",
    "\n",
    "personal = [\"gmail.com\", \"yahoo.com\", \"protonmail.com\"]\n",
    "\n",
    "junk = [\"me.com\", \"aol.com\", \"hotmail.com\", \"live.com\", \"msn.com\", \"passport.com\"]\n",
    "\n",
    "# Split by @ and select domains\n",
    "chef['EMAIL_DOMAIN'] = chef.EMAIL.str.split('@', expand=True)[1]\n",
    "\n",
    "# Create email_type column\n",
    "chef['EMAIL_TYPE'] = '0'\n",
    "\n",
    "# Populate the Email Type column by if else statements\n",
    "for index, row in chef.iterrows():\n",
    "\n",
    "    if chef.loc[index, 'EMAIL_DOMAIN'] in professional:\n",
    "        chef.loc[index, 'EMAIL_TYPE'] = 'professional'\n",
    "    elif chef.loc[index, 'EMAIL_DOMAIN'] in personal:\n",
    "        chef.loc[index, 'EMAIL_TYPE'] = 'personal'\n",
    "    elif chef.loc[index, 'EMAIL_DOMAIN'] in junk:\n",
    "        chef.loc[index, 'EMAIL_TYPE'] = 'junk'\n",
    "    elif chef.loc[index, 'EMAIL_DOMAIN'] not in professional or chef.loc[row, 'EMAIL'] not in personal or chef.loc[row, 'EMAIL'] not in junk:\n",
    "        chef.loc[index, 'EMAIL_TYPE'] = 'unknown'\n",
    "    else:\n",
    "        print('Houston, we have a problem')\n",
    "\n",
    "# Checking results\n",
    "chef['EMAIL_TYPE'].value_counts()\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "# personal        861\n",
    "# professional    696\n",
    "# junk            389\n",
    "# Name: EMAIL_TYPE, dtype: int64\n",
    "\n",
    "# Distribution of Email Type\n",
    "# categorical_boxplots(response = 'LOG_REVENUE', cat_var = 'EMAIL_TYPE', data = chef)\n",
    "\n",
    "# one hot encoding categorical variable\n",
    "EMAIL_TYPE_DUMMIES       = pd.get_dummies(chef['EMAIL_TYPE'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "chef = chef.drop('EMAIL_TYPE', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "chef = chef.join([EMAIL_TYPE_DUMMIES])\n",
    "\n",
    "# saving new columns\n",
    "new_columns = chef.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable counting the number of names in NAME column        \n",
    "text_split_feature(col = 'NAME', df = chef, new_col_name = 'NUMBER_NAMES' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable to flag when FIRST NAME == FAMILY NAME\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,col in chef.iterrows():\n",
    "    if chef.loc[row,'FIRST_NAME'] == chef.loc[row,'FAMILY_NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "# Adding the new variable to the dataset\n",
    "chef['SAME_NAME'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable to flag NOBLE customers\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,pattern in chef.iterrows():\n",
    "    if ' of ' in chef.loc[row,'NAME'] or \\\n",
    "    'lord' in chef.loc[row,'NAME'] or \\\n",
    "    'Lord' in chef.loc[row,'NAME'] or \\\n",
    "    ' mo ' in chef.loc[row,'NAME'] or \\\n",
    "    ' zo ' in chef.loc[row,'NAME'] or \\\n",
    "    ' Mo ' in chef.loc[row,'NAME'] or \\\n",
    "    'Knight' in chef.loc[row, 'NAME'] or \\\n",
    "    'knight'in chef.loc[row, 'NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "chef['NOBLE'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables for customers who have attended master classes\n",
    "chef['HAS_ATTENDED_MASTER_CLASS']   = 0\n",
    "\n",
    "# Iterating over original columns to change values in the new feature columns\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    # Has Attended Master Classes     \n",
    "    if chef.loc[index, 'MASTER_CLASSES_ATTENDED'] > 0:\n",
    "        chef.loc[index, 'HAS_ATTENDED_MASTER_CLASS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "chef_data = chef.drop(['CROSS_SELL_SUCCESS', 'NAME',\n",
    "                      'EMAIL', 'FIRST_NAME', 'FAMILY_NAME', 'EMAIL_DOMAIN','m_FAMILY_NAME', 'unknown', \n",
    "                       'personal', 'TOTAL_MEALS_ORDERED'], axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "chef_target = chef.loc [ : , 'CROSS_SELL_SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_data,\n",
    "            chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "chef_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "#logit_sig = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~ \n",
    "#                                     MOBILE_NUMBER + \n",
    "#                                     CANCELLATIONS_BEFORE_NOON +\n",
    "#                                     TASTES_AND_PREFERENCES +  \n",
    "#                                     MOBILE_LOGINS +\n",
    "#                                     EARLY_DELIVERIES +\n",
    "#                                     REFRIGERATED_LOCKER +\n",
    "#                                     USE_MOBILE_APP + \n",
    "#                                     female +\n",
    "#                                     junk +  \n",
    "#                                     professional +\n",
    "#                                     SAME_NAME +\n",
    "#                                     HAS_ATTENDED_MASTER_CLASS\"\"\",\n",
    "#                                            data    = chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "#logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "#logit_sig.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of dictionary & Train Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH', 'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'PRODUCT_CATEGORIES_VIEWED', 'AVG_TIME_PER_SITE_VISIT', 'MOBILE_NUMBER', \n",
    "                   'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES', \n",
    "                   'PC_LOGINS', 'MOBILE_LOGINS', 'WEEKLY_PLAN', 'EARLY_DELIVERIES', 'LATE_DELIVERIES', \n",
    "                   'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER', 'AVG_PREP_VID_TIME', 'AVG_NB_MEALS', \n",
    "                   'MASTER_CLASSES_ATTENDED', 'MEDIAN_MEAL_RATING', 'AVG_CLICKS_PER_VISIT', \n",
    "                   'TOTAL_PHOTOS_VIEWED','USE_MOBILE_APP', 'female', 'male', 'unknown', \n",
    "                   'junk', 'personal', 'NUMBER_NAMES', 'SAME_NAME', 'NOBLE', 'HAS_ATTENDED_MASTER_CLASS'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', \n",
    "                   'TASTES_AND_PREFERENCES', 'MOBILE_LOGINS','EARLY_DELIVERIES', \n",
    "                   'REFRIGERATED_LOCKER', 'AVG_PREP_VID_TIME', 'USE_MOBILE_APP','female', 'junk', \n",
    "                   'professional', 'NUMBER_NAMES', 'SAME_NAME', 'NOBLE', 'HAS_ATTENDED_MASTER_CLASS'],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the sig model\n",
    "chef_data   =  chef.loc[ : , dict1['logit_sig']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# Train test split with the significant variables\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_data,\n",
    "            chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "chef_data_full   =  chef.loc[ : , dict1['logit_full']]\n",
    "chef_target_full =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# Train test split with the full dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            chef_data_full,\n",
    "            chef_target_full,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_target_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide a scaled data set into train and test variable\n",
    "\n",
    "chef_data_full   =  chef.loc[ : , dict1['logit_full']]\n",
    "chef_target_full =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FITTING the independent variable data\n",
    "scaler.fit(chef_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the independent variable data\n",
    "X_scaled     = scaler.transform(chef_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_scaled_chef  = pd.DataFrame(X_scaled) \n",
    "\n",
    "\n",
    "# Train test split with all the scaled data\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "                    X_scaled_chef,\n",
    "                    chef_target_full,\n",
    "                    random_state = 219,\n",
    "                    test_size = 0.25,\n",
    "                    stratify = chef_target_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7608\n",
      "Testing Score: 0.7618\n",
      "AUC Score: 0.6858\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            max_iter = 500,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Score:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing Score:', logreg_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4) #auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 74\n",
      "False Positives: 82\n",
      "False Negatives: 34\n",
      "True Positives : 297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7622\n",
      "Testing  ACCURACY: 0.7618\n",
      "AUC Score        : 0.6875\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 4,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = logreg_pred).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ecd2318cd68f>:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  C_space          = pd.np.arange(1.0, 10.0, 100.0)\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/arlinegarin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'warm_start': True, 'solver': 'liblinear', 'C': 1.0}\n",
      "Tuned CV AUC      : 0.6792\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "C_space          = pd.np.arange(1.0, 10.0, 100.0)\n",
    "warm_start_space = [True, False]\n",
    "solver_space     = ['newton-cg', 'sag', 'lbfgs', 'liblinear']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_space,\n",
    "              'warm_start' : warm_start_space,\n",
    "              'solver'     : solver_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219,\n",
    "                              max_iter     = 5000)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 8,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(chef_data_full, chef_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Tuned Training ACCURACY: 0.767\n",
      "LR Tuned Testing  ACCURACY: 0.7762\n",
      "LR Tuned AUC Score        : 0.7015\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = lr_tuned_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(X_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(X_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(X_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 77\n",
      "False Positives: 79\n",
      "False Negatives: 30\n",
      "True Positives : 301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(X_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(X_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Tuned LR'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, lr_auc],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, lr_train_acc],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, lr_test_acc],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (lr_tuned_tn, lr_tuned_fp, lr_tuned_fn, lr_tuned_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training Score: 1.0\n",
      "Full Tree Testing Score : 0.6263\n",
      "Full Tree AUC Score: 0.5861\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training Score:', full_tree_fit.score(X_train,\n",
    "                                                    y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing Score :', full_tree_fit.score(X_test,\n",
    "                                                    y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(X_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 74\n",
      "False Positives: 82\n",
      "False Negatives: 100\n",
      "True Positives : 231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Full Tree',\n",
    "                           'Training Accuracy' : full_tree_train_score,\n",
    "                           'Testing Accuracy'  : full_tree_test_score,\n",
    "                           'AUC Score'         : full_tree_auc_score,\n",
    "                           'Confusion Matrix'  : (full_tree_tn,\n",
    "                                                    full_tree_fp,\n",
    "                                                    full_tree_fn,\n",
    "                                                    full_tree_tp)},\n",
    "                           ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7409\n",
      "Testing  ACCURACY: 0.7762\n",
      "AUC Score        : 0.732\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth = 3,\n",
    "                    min_samples_leaf = 25,\n",
    "                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = tree_pruned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(X_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(X_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 95\n",
      "False Positives: 61\n",
      "False Negatives: 48\n",
      "True Positives : 283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>(74, 82, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(77, 79, 30, 301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>(74, 82, 100, 231)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(95, 61, 48, 283)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0     Logistic     0.6858             0.7608            0.7618   (74, 82, 34, 297)\n",
       "1     Tuned LR     0.7015             0.7670            0.7762   (77, 79, 30, 301)\n",
       "2    Full Tree     0.5861             1.0000            0.6263  (74, 82, 100, 231)\n",
       "3  Pruned Tree     0.7320             0.7409            0.7762   (95, 61, 48, 283)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Pruned Tree',\n",
    "                           'Training Accuracy' : pruned_tree_train_score,\n",
    "                           'Testing Accuracy'  : pruned_tree_test_score,\n",
    "                           'AUC Score'         : pruned_tree_auc_score,\n",
    "                           'Confusion Matrix'  : (pruned_tree_tn,\n",
    "                                                    pruned_tree_fp,\n",
    "                                                    pruned_tree_fn,\n",
    "                                                    pruned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning On Classification Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-13e780f9600f>:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  depth_space     = pd.np.arange(1, 8, 1)\n",
      "<ipython-input-40-13e780f9600f>:5: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  leaf_space      = pd.np.arange(1, 100, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'best', 'min_samples_leaf': 8, 'max_depth': 3, 'criterion': 'entropy'}\n",
      "Tuned Training AUC: 0.704\n"
     ]
    }
   ],
   "source": [
    "# declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 8, 1)\n",
    "leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 8,\n",
    "                                   n_iter                = 250,\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(chef_data_full, chef_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7409\n",
      "Testing  ACCURACY: 0.7762\n",
      "AUC Score        : 0.732\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = tuned_tree_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(X_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 95\n",
      "False Positives: 61\n",
      "False Negatives: 48\n",
      "True Positives : 283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(X_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(X_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells for the Random Forest Model are not being run as the scores are not relevant enough for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "#rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "#                                    criterion        = 'gini',\n",
    "#                                    max_depth        = 4,\n",
    "#                                    min_samples_leaf = 1,\n",
    "#                                    bootstrap        = True,\n",
    "#                                    warm_start       = False,\n",
    "#                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "#print('Training Random Forest:', rf_default_fit.score(X_train, y_train).round(4))\n",
    "#print('Testing  Random Forest:', rf_default_fit.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "#print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "#rf_tn, \\\n",
    "#rf_fp, \\\n",
    "#rf_fn, \\\n",
    "#rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "#print(f\"\"\"\n",
    "#True Negatives : {rf_tn}\n",
    "#False Positives: {rf_fp}\n",
    "#False Negatives: {rf_fn}\n",
    "#True Positives : {rf_tp}\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "#rf_train_acc = rf_default_fit.score(X_train, y_train).round(4)\n",
    "#rf_test_acc  = rf_default_fit.score(X_test, y_test).round(4)\n",
    "#rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "#                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "#model_performance = model_performance.append(\n",
    "#                          {'Model Name'         : 'Random Forest (Full)',\n",
    "#                           'Training Accuracy'  : rf_train_acc,\n",
    "#                           'Testing Accuracy'   : rf_test_acc,\n",
    "#                           'AUC Score'          : rf_auc,\n",
    "#                           'Confusion Matrix'   : (rf_tn,\n",
    "#                                                   rf_fp,\n",
    "#                                                   rf_fn,\n",
    "#                                                   rf_tp)},\n",
    "#                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "#model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#estimator_space  = pd.np.arange(100, 500, 250)\n",
    "#leaf_space       = pd.np.arange(1, 31, 10)\n",
    "#criterion_space  = ['gini', 'entropy']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'n_estimators'     : estimator_space,\n",
    "#              'min_samples_leaf' : leaf_space,\n",
    "#              'criterion'        : criterion_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                               param_distributions = param_grid,\n",
    "#                               cv         = 6,\n",
    "#                               n_iter     = 12,\n",
    "#                               scoring    = make_scorer(roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#forest_cv.fit(chef_data_full, chef_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "#forest_tuned = forest_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#forest_tuned_pred = forest_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "#print('Training Forest Tuned:', forest_tuned.score(X_train, y_train).round(4))\n",
    "#print('Testing Forest Tuned :', forest_tuned.score(X_test, y_test).round(4))\n",
    "#print('AUC Score Forest Tuned        :', roc_auc_score(y_true  = y_test,\n",
    "#                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "#forest_tuned_train_score = forest_tuned.score(X_train, y_train).round(4) # accuracy\n",
    "#forest_tuned_test_score  = forest_tuned.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "#forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "#                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "#tuned_rf_tn, \\\n",
    "#tuned_rf_fp, \\\n",
    "#tuned_rf_fn, \\\n",
    "#tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "#print(f\"\"\"\n",
    "#True Negatives : {tuned_rf_tn}\n",
    "#False Positives: {tuned_rf_fp}\n",
    "#False Negatives: {tuned_rf_fn}\n",
    "#True Positives : {tuned_rf_tp}\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "#tuned_rf_train_acc = forest_tuned.score(X_train, y_train).round(4)\n",
    "#tuned_rf_test_acc  = forest_tuned.score(X_test, y_test).round(4)\n",
    "#tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "#                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "#model_performance = model_performance.append(\n",
    "#                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "#                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "#                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "#                           'AUC Score'          : tuned_rf_auc,\n",
    "#                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "#                                                   tuned_rf_fp,\n",
    "#                                                   tuned_rf_fn,\n",
    "#                                                   tuned_rf_tp)},\n",
    "#                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "#model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.904\n",
      "Testing  ACCURACY: 0.7454\n",
      "AUC Score        : 0.6619\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification \n",
    "g_boost = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     criterion = 'friedman_mse',\n",
    "                                     learning_rate =  0.1,\n",
    "                                     n_estimators = 100,\n",
    "                                     max_depth = 4,\n",
    "                                     random_state  = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "g_boost_fit = g_boost.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "g_boost_pred = g_boost_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', g_boost_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', g_boost_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = g_boost_pred).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 67\n",
      "False Positives: 89\n",
      "False Negatives: 35\n",
      "True Positives : 296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = g_boost_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING the model\n",
    "gbm_train_acc = g_boost_fit.score(X_train, y_train).round(4)\n",
    "gbm_test_acc  = g_boost_fit.score(X_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = g_boost_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM - Full',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-7cb13a22c9d9>:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  learn_space        = pd.np.arange(0.1, 2.0, 0.2) # play with this one\n",
      "<ipython-input-55-7cb13a22c9d9>:3: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  estimator_space    = pd.np.arange(50, 100, 25) # play with this one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'n_estimators': 50, 'learning_rate': 0.30000000000000004}\n",
      "Tuned Training AUC: 0.6412\n"
     ]
    }
   ],
   "source": [
    "# declaring a hyperparameter space\n",
    "learn_space        = pd.np.arange(0.1, 2.0, 0.2) # play with this one\n",
    "estimator_space    = pd.np.arange(50, 100, 25) # play with this one\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'learning_rate' : learn_space,\n",
    "              'n_estimators'  : estimator_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_grid = GradientBoostingClassifier(max_depth = 4,\n",
    "                                           random_state  = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "full_gbm_cv = RandomizedSearchCV(estimator = full_gbm_grid,\n",
    "                                 param_distributions = param_grid,\n",
    "                                 cv                  = 3,\n",
    "                                 n_iter              = 20,\n",
    "                                 random_state        = 219,\n",
    "                                 scoring             = make_scorer(roc_auc_score,\n",
    "                                                       needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "full_gbm_cv.fit(chef_data_full, chef_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9191\n",
      "Testing  ACCURACY: 0.9322\n",
      "AUC Score        : 0.9061\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = full_gbm_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 130\n",
      "False Positives: 26\n",
      "False Negatives: 7\n",
      "True Positives : 324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "gbm_tuned_train_acc = gbm_tuned.score(X_train, y_train).round(4)\n",
    "gbm_tuned_test_acc  = gbm_tuned.score(X_test, y_test).round(4)\n",
    "gbm_tuned_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : '**Tuned GBM (final model)',\n",
    "                          'Training Accuracy'  : gbm_tuned_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_tuned_test_acc,\n",
    "                          'AUC Score'          : gbm_tuned_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('./classification_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>**Tuned GBM (final model)</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>(130, 26, 7, 324)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(95, 61, 48, 283)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(95, 61, 48, 283)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(77, 79, 30, 301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>(74, 82, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM - Full</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.7454</td>\n",
       "      <td>(67, 89, 35, 296)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>(74, 82, 100, 231)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "6  **Tuned GBM (final model)     0.9061             0.9191            0.9322   (130, 26, 7, 324)\n",
       "3                Pruned Tree     0.7320             0.7409            0.7762   (95, 61, 48, 283)\n",
       "4                 Tuned Tree     0.7320             0.7409            0.7762   (95, 61, 48, 283)\n",
       "1                   Tuned LR     0.7015             0.7670            0.7762   (77, 79, 30, 301)\n",
       "0                   Logistic     0.6858             0.7608            0.7618   (74, 82, 34, 297)\n",
       "5                 GBM - Full     0.6619             0.9040            0.7454   (67, 89, 35, 296)\n",
       "2                  Full Tree     0.5861             1.0000            0.6263  (74, 82, 100, 231)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MODEL OUTPUTS\n",
      "-------------\n",
      "\n",
      "Model Name              AUC Score         Training Accuracy      Testing Accuracy      Confusion Matrix\n",
      "----------              ---------         -----------------      ----------------      ----------------\n",
      "Logistic                0.6858            0.7608                 0.7618                (74, 82, 34, 297)\n",
      "Tuned LR                0.7015            0.767                  0.7762                (77, 79, 30, 301)\n",
      "Full Tree               0.5861            1.0                    0.6263                (74, 82, 100, 231)\n",
      "Pruned Tree             0.732             0.7409                 0.7762                (95, 61, 48, 283)\n",
      "Tuned Tree              0.732             0.7409                 0.7762                (95, 61, 48, 283)\n",
      "GBM - Full              0.6619            0.904                  0.7454                (67, 89, 35, 296)\n",
      "*Tuned GBM (final)      0.9061            0.9191                 0.9322                (130, 26, 7, 324)\n",
      "\n",
      "** The best model is the Tuned GBM Model with the full dataset and a AUC score of 0.9061. \n",
      "The train test-gap is 0.0131.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "MODEL OUTPUTS\n",
    "-------------\n",
    "\n",
    "Model Name              AUC Score         Training Accuracy      Testing Accuracy      Confusion Matrix\n",
    "----------              ---------         -----------------      ----------------      ----------------\n",
    "Logistic                {logreg_auc_score}            {logreg_train_score}                 {logreg_test_score}                {(logreg_tn, logreg_fp, logreg_fn, logreg_tp)}\n",
    "Tuned LR                {lr_auc}            {lr_train_acc}                  {lr_test_acc}                {(lr_tuned_tn, lr_tuned_fp, lr_tuned_fn, lr_tuned_tp)}\n",
    "Full Tree               {full_tree_auc_score}            {full_tree_train_score}                    {full_tree_test_score}                {(full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp)}\n",
    "Pruned Tree             {pruned_tree_auc_score}             {pruned_tree_train_score}                 {pruned_tree_test_score}                {(pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)}\n",
    "Tuned Tree              {tree_auc}             {tree_train_acc}                 {tree_test_acc}                {(tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp)}\n",
    "GBM - Full              {gbm_auc}            {gbm_train_acc}                  {gbm_test_acc}                {(gbm_default_tn, gbm_default_fp, gbm_default_fn, gbm_default_tp)}\n",
    "*Tuned GBM (final)      {gbm_tuned_auc}            {gbm_tuned_train_acc}                 {gbm_tuned_test_acc}                {(gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp)}\n",
    "\n",
    "** The best model is the Tuned GBM Model with the full dataset and a AUC score of 0.9061. \n",
    "The train test-gap is 0.0131.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
